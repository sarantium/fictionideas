## One Hour PM

I'm building a library - a work in progress which I'm calling **One Hour PM** - that uses generative AI agents to help product managers accelerate value creation and capture. It does this by exploring how agents and automations can improve **creative** and **productive** ways of working with product ideas and tasks.

The library has the following key features:

- **Simple**: One input interface across all tasks
- **Multimodal**: Inputs and outputs work with many data types
- **Curated**: Modern product tools and templates selected with a bias for lean workflows
- **Contextual**: Add custom data sources for more specific and specialised outcomes
- **Connected**: Access to internal and external tools
- **Automatic**: Agents execute creative and directed tasks semi-autonomously
- **Fast**: Compressing task cycle times to minutes and workflow cycle times to an hour
- **Solo**: Get more done with only yourself-in-the-loop
- **Safe**: Validated output that enforces structure and reliability

## Tips and Tricks

| Stage                    | Tips & Tricks                                                                                                                                                                                                                                                                                                                                                                      |
| ------------------------ | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Planning & Design**    | - **Iterative Loop:**<br> • Chat: Explore options<br> • Play: Edit in OpenAI playground (60% time)<br> • Loop: Add data and test cases<br> • Nest: Simplify with subtasks<br>- **Time Allocation:**<br> • Playing: 60%<br> • Prompt Tuning: 20%<br> • Input Massaging: 10%<br> • Coding: 10%<br> • Tooling: 1%                                                                     |
| **Development**          | - **Dos:**<br> • Use all modalities<br> • Code for input and output structure<br> • Leverage pretraining information<br> • Reduce search space upfront<br>- **Don'ts:**<br> • Add abstractions between yourself and the LLM<br> • Stick to one model<br> • Have too high an I/O ratio                                                                                              |
| **Testing & Debugging**  | - **Debugging:**<br> • Start at the prompt level or try a different model<br> • Transform input and add more structure to output<br> • Classify tasks and errors to identify where the failure is<br>- **Optimizing AI:**<br> • Break prompts to reduce complexity<br> • Use separate models for structure and long-form writing<br> • Implement state management and self-healing |
| **Deployment & Scaling** | - **Future Planning:**<br> • Assume everything will be 10x to 50x cheaper and faster in the future<br> • Build for at least 6 months ahead<br>- **AI Resources:**<br> • Be mindful of the exponential scaling of attention algorithms                                                                                                                                              |
